# CNN-on-MNIST-datset
CNN on MNIST dataset. The data is there in the repository. Also, I uploaded 2 different Implementations, One of them is using PyTorch.

MNIST data - Download the dataset of hand-written digits
http : //yann.lecun.com/exdb/mnist/
containing 10 classes. [Reduce the number of samples in training data if your computing
powers are limited as required by random subsampling]. The Keras package is needed for
the rest of the question https : //pypi.python.org/pypi/Keras
Use the Keras package to implement a CNN model with 2 layers of Convolutions and 1
layer of feedforward archictures. The CNN layers have 64 kernels of size 3 × 3, stride of
1, 1 and maxpooling component of 2 × 2. The feedforward layer has 256 neurons. What
is the performance on the test dataset for this classifier. Can you implement the model
with and without weight regularization (L2 regularization with weight of 0.2), with and
without dropout (10%). Further, comment on the training/validation loss function as
well as the test accuracy with (i) SGD, (ii) RMSprop and (iii) Adam optimizer. (Points
30)


Both of the implementations report is there with outputs. If anyone have any kind of doubt or something, please to mail me at

anshulshivha@iisc.ac.in 
shivhareanshul78@gmail.com
