{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import gzip\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# with gzip.open('train-images-idx3-ubyte.gz', 'r') as f:\n",
    "#     m = int.from_bytes(f.read(4), 'big')\n",
    "#     img_count = int.from_bytes(f.read(4), 'big')\n",
    "#     r = int.from_bytes(f.read(4), 'big')\n",
    "#     c = int.from_bytes(f.read(4), 'big')\n",
    "#     train_image_data = f.read()\n",
    "#     train_images = np.frombuffer(train_image_data, dtype=np.uint8)\\\n",
    "#         .reshape((img_count, r, c))\n",
    "\n",
    "# with gzip.open('train-labels-idx1-ubyte.gz', 'r') as f:\n",
    "#     m = int.from_bytes(f.read(4), 'big')\n",
    "#     l = int.from_bytes(f.read(4), 'big')\n",
    "#     train_ = f.read()\n",
    "#     l_train = np.frombuffer(train_label_data, dtype=np.uint8)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not platform.system() == 'Windows':\n",
    "#     x_train, y_train = loadlocal_mnist(\n",
    "#             images_path='train-images-idx3-ubyte', \n",
    "#             labels_path='train-labels-idx1-ubyte')\n",
    "\n",
    "# else:\n",
    "#     x_train, y_train = loadlocal_mnist(\n",
    "#             images_path='train-images.idx3-ubyte', \n",
    "#             labels_path='train-labels.idx1-ubyte')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not platform.system() == 'Windows':\n",
    "#     x_test, y_test = loadlocal_mnist(\n",
    "#             images_path='t10k-images-idx3-ubyte', \n",
    "#             labels_path='t10k-labels-idx1-ubyte')\n",
    "\n",
    "# else:\n",
    "#     x_test, y_test = loadlocal_mnist(\n",
    "#             images_path='t10k-images.idx3-ubyte', \n",
    "#             labels_path='t10k-labels.idx1-ubyte')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist= tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train),(x_test,y_test)= mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "(60000,)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize\n",
    "x_train =tf.keras.utils.normalize(x_train,axis=1)\n",
    "x_test= tf.keras.utils.normalize(x_test,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training sample dimesion (60000, 28, 28, 1)\n",
      "training sample dimesion (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "IMG_SIZE=28\n",
    "x_trainr=np.array(x_train).reshape(-1,IMG_SIZE,IMG_SIZE,1)\n",
    "x_testr=np.array(x_test).reshape(-1,IMG_SIZE,IMG_SIZE,1)\n",
    "print(\"training sample dimesion\",x_trainr.shape)\n",
    "print(\"training sample dimesion\",x_testr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten,Conv2D,MaxPooling2D\n",
    "from keras.regularizers import l2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For optimizer adam\n",
    "class CNN1():\n",
    "    def __init__(self,Dropout):\n",
    "        self.Dropout=Dropout\n",
    "   \n",
    "\n",
    "    def withRegularization(self):\n",
    "        \n",
    "        #shape=images.size()\n",
    "        model=Sequential()\n",
    "        model.add(Conv2D(64,(3,3),strides=1,input_shape=x_trainr.shape[1:]))\n",
    "        \n",
    "        \n",
    "        \n",
    "        model.add(Conv2D(32,(3,3),strides=1, input_shape=x_trainr.shape[1:]))\n",
    "        model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Flatten())\n",
    "        \n",
    "        #model.add(Dense(256, activation='relu',kernel_regularizer=l2(0.2)))\n",
    "        model.add(Dense(256, kernel_regularizer=l2(0.01)))\n",
    "\n",
    "        model.add(Activation(\"relu\"))\n",
    "        \n",
    "        \n",
    "        if self.Dropout:\n",
    "            model.add(Dropout(0.1))\n",
    "        model.add(Dense(10))\n",
    "        \n",
    "        model.add(Activation(\"softmax\"))\n",
    "        model.compile(loss=\"sparse_categorical_crossentropy\", optimizer =\"adam\", metrics=['accuracy'])\n",
    "        history=model.fit(x_trainr,y_train,batch_size=32,epochs=2, validation_data=(x_testr,y_test))\n",
    "        \n",
    "        print(history.history.keys())\n",
    "        plt.plot(history.history['accuracy'])\n",
    "        plt.plot(history.history['val_accuracy'])\n",
    "        plt.title('model accuracy')\n",
    "        plt.ylabel('accuracy')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'test'], loc='upper left')\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "        # summarize history for loss\n",
    "        plt.plot(history.history['loss'])\n",
    "        plt.plot(history.history['val_loss'])\n",
    "        plt.title('model loss')\n",
    "        plt.ylabel('loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'test'], loc='upper left')\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "        \n",
    "    def withoutRegularization(self):\n",
    "        model=Sequential()\n",
    "        model.add(Conv2D(64,(3,3),strides=1,input_shape=x_trainr.shape[1:]))\n",
    "        \n",
    "        \n",
    "        \n",
    "        model.add(Conv2D(32,(3,3),strides=1, input_shape=x_trainr.shape[1:]))\n",
    "        model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Flatten())\n",
    "        \n",
    "        \n",
    "        model.add(Dense(256, activation='relu'))\n",
    "        \n",
    "        if self.Dropout:\n",
    "            model.add(Dropout(0.1))\n",
    "        model.add(Dense(10))\n",
    "        model.add(Activation(\"softmax\"))\n",
    "        model.compile(loss=\"sparse_categorical_crossentropy\", optimizer =\"adam\", metrics=['accuracy'])\n",
    "        history=model.fit(x_trainr,y_train,batch_size=32,epochs=2, validation_data=(x_testr,y_test))\n",
    "        \n",
    "        print(history.history.keys())\n",
    "        plt.plot(history.history['accuracy'])\n",
    "        plt.plot(history.history['val_accuracy'])\n",
    "        plt.title('model accuracy')\n",
    "        plt.ylabel('accuracy')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'test'], loc='upper left')\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "        # summarize history for loss\n",
    "        plt.plot(history.history['loss'])\n",
    "        plt.plot(history.history['val_loss'])\n",
    "        plt.title('model loss')\n",
    "        plt.ylabel('loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'test'], loc='upper left')\n",
    "        plt.show()\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1=CNN1(Dropout=False)\n",
    "model1.withRegularization()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1=CNN1(Dropout=True)\n",
    "model1.withRegularization()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1=CNN1(Dropout=False)\n",
    "model1.withoutRegularization()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1=CNN1(Dropout=True)\n",
    "model1.withoutRegularization()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For optimizer sgd\n",
    "class CNN2():\n",
    "    def __init__(self,Dropout):\n",
    "        self.Dropout=Dropout\n",
    "   \n",
    "\n",
    "    def withRegularization(self):\n",
    "        \n",
    "        #shape=images.size()\n",
    "        model=Sequential()\n",
    "        model.add(Conv2D(64,(3,3),strides=1,input_shape=x_trainr.shape[1:]))\n",
    "        \n",
    "        \n",
    "        \n",
    "        model.add(Conv2D(32,(3,3),strides=1, input_shape=x_trainr.shape[1:]))\n",
    "        model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Flatten())\n",
    "        \n",
    "        #model.add(Dense(256, activation='relu',kernel_regularizer=l2(0.2)))\n",
    "        model.add(Dense(256, kernel_regularizer=l2(0.01)))\n",
    "\n",
    "        model.add(Activation(\"relu\"))\n",
    "        \n",
    "        \n",
    "        if self.Dropout:\n",
    "            model.add(Dropout(0.1))\n",
    "        model.add(Dense(10))\n",
    "        \n",
    "        model.add(Activation(\"softmax\"))\n",
    "        model.compile(loss=\"sparse_categorical_crossentropy\", optimizer =\"sgd\", metrics=['accuracy'])\n",
    "        history=model.fit(x_trainr,y_train,batch_size=32,epochs=2, validation_data=(x_testr,y_test))\n",
    "        \n",
    "        print(history.history.keys())\n",
    "        plt.plot(history.history['accuracy'])\n",
    "        plt.plot(history.history['val_accuracy'])\n",
    "        plt.title('model accuracy')\n",
    "        plt.ylabel('accuracy')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'test'], loc='upper left')\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "        # summarize history for loss\n",
    "        plt.plot(history.history['loss'])\n",
    "        plt.plot(history.history['val_loss'])\n",
    "        plt.title('model loss')\n",
    "        plt.ylabel('loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'test'], loc='upper left')\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "    def withoutRegularization(self):\n",
    "        model=Sequential()\n",
    "        model.add(Conv2D(64,(3,3),strides=1,input_shape=x_trainr.shape[1:]))\n",
    "        \n",
    "        \n",
    "        \n",
    "        model.add(Conv2D(32,(3,3),strides=1, input_shape=x_trainr.shape[1:]))\n",
    "        model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Flatten())\n",
    "        \n",
    "        \n",
    "        model.add(Dense(256, activation='relu'))\n",
    "        \n",
    "        if self.Dropout:\n",
    "            model.add(Dropout(0.1))\n",
    "        model.add(Dense(10))\n",
    "        model.add(Activation(\"softmax\"))\n",
    "        model.compile(loss=\"sparse_categorical_crossentropy\", optimizer =\"sgd\", metrics=['accuracy'])\n",
    "        history=model.fit(x_trainr,y_train,batch_size=32,epochs=2, validation_data=(x_testr,y_test))\n",
    "        \n",
    "        \n",
    "        print(history.history.keys())\n",
    "        plt.plot(history.history['accuracy'])\n",
    "        plt.plot(history.history['val_accuracy'])\n",
    "        plt.title('model accuracy')\n",
    "        plt.ylabel('accuracy')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'test'], loc='upper left')\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "        # summarize history for loss\n",
    "        plt.plot(history.history['loss'])\n",
    "        plt.plot(history.history['val_loss'])\n",
    "        plt.title('model loss')\n",
    "        plt.ylabel('loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'test'], loc='upper left')\n",
    "        plt.show()\n",
    "        \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      " 602/1875 [========>.....................] - ETA: 2:06 - loss: 5.3512 - accuracy: 0.7194"
     ]
    }
   ],
   "source": [
    "model2=CNN2(Dropout=False)\n",
    "model2.withRegularization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2=CNN2(Dropout=True)\n",
    "model2.withRegularization()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2=CNN2(Dropout=False)\n",
    "model2.withoutRegularization()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2=CNN2(Dropout=True)\n",
    "model2.withoutRegularization()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For optimizer Rmsprop\n",
    "class CNN3():\n",
    "    def __init__(self,Dropout):\n",
    "        self.Dropout=Dropout\n",
    "   \n",
    "\n",
    "    def withRegularization(self):\n",
    "        \n",
    "        #shape=images.size()\n",
    "        model=Sequential()\n",
    "        model.add(Conv2D(64,(3,3),strides=1,input_shape=x_trainr.shape[1:]))\n",
    "        \n",
    "        \n",
    "        \n",
    "        model.add(Conv2D(32,(3,3),strides=1, input_shape=x_trainr.shape[1:]))\n",
    "        model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Flatten())\n",
    "        \n",
    "        #model.add(Dense(256, activation='relu',kernel_regularizer=l2(0.2)))\n",
    "        model.add(Dense(256, kernel_regularizer=l2(0.01)))\n",
    "\n",
    "        model.add(Activation(\"relu\"))\n",
    "        \n",
    "        \n",
    "        if self.Dropout:\n",
    "            model.add(Dropout(0.1))\n",
    "        model.add(Dense(10))\n",
    "        \n",
    "        model.add(Activation(\"softmax\"))\n",
    "        model.compile(loss=\"sparse_categorical_crossentropy\", optimizer =\"RMSprop\", metrics=['accuracy'])\n",
    "        history=model.fit(x_trainr,y_train,batch_size=32,epochs=2, validation_data=(x_testr,y_test))\n",
    "        \n",
    "        print(history.history.keys())\n",
    "        plt.plot(history.history['accuracy'])\n",
    "        plt.plot(history.history['val_accuracy'])\n",
    "        plt.title('model accuracy')\n",
    "        plt.ylabel('accuracy')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'test'], loc='upper left')\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "        # summarize history for loss\n",
    "        plt.plot(history.history['loss'])\n",
    "        plt.plot(history.history['val_loss'])\n",
    "        plt.title('model loss')\n",
    "        plt.ylabel('loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'test'], loc='upper left')\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "    def withoutRegularization(self):\n",
    "        model=Sequential()\n",
    "        model.add(Conv2D(64,(3,3),strides=1,input_shape=x_trainr.shape[1:]))\n",
    "        \n",
    "        \n",
    "        \n",
    "        model.add(Conv2D(32,(3,3),strides=1, input_shape=x_trainr.shape[1:]))\n",
    "        model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Flatten())\n",
    "        \n",
    "        \n",
    "        model.add(Dense(256, activation='relu'))\n",
    "        \n",
    "        if self.Dropout:\n",
    "            model.add(Dropout(0.1))\n",
    "        model.add(Dense(10))\n",
    "        model.add(Activation(\"softmax\"))\n",
    "        model.compile(loss=\"sparse_categorical_crossentropy\", optimizer =\"RMSprop\", metrics=['accuracy'])\n",
    "        history=model.fit(x_trainr,y_train,batch_size=32,epochs=2, validation_data=(x_testr,y_test))\n",
    "        \n",
    "        print(history.history.keys())\n",
    "        plt.plot(history.history['accuracy'])\n",
    "        plt.plot(history.history['val_accuracy'])\n",
    "        plt.title('model accuracy')\n",
    "        plt.ylabel('accuracy')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'test'], loc='upper left')\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "        # summarize history for loss\n",
    "        plt.plot(history.history['loss'])\n",
    "        plt.plot(history.history['val_loss'])\n",
    "        plt.title('model loss')\n",
    "        plt.ylabel('loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'test'], loc='upper left')\n",
    "        plt.show()\n",
    "        \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3=CNN3(Dropout=False)\n",
    "model3.withRegularization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3=CNN3(Dropout=True)\n",
    "model3.withRegularization()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3=CNN3(Dropout=False)\n",
    "model3.withoutRegularization()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3=CNN3(Dropout=True)\n",
    "model3.withoutRegularization()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: I Trained my models for only 2 epochs as it was taking a lot of time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
